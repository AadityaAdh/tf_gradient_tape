{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfVe8RWSo4IQ1jqjHttB0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AadityaAdh/tf_gradient_tape/blob/main/gradient_tapee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient tape:\n",
        "used to calculate gardient or derivative\n",
        "syntax:\n",
        "\n",
        "    with tf.gradienttape as tape:\n",
        "      y=x**2\n",
        "\n",
        "\n",
        "note:tape vanae ko chai yesari samjhini ki yellae chai record rakhxa\n",
        "matlab mathi ko eg ma yo tape recording ma chai x ko y sanga ko relation sabbai record vai raa xa\n",
        "    "
      ],
      "metadata": {
        "id": "GgWetsZ8rZqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "uyRIkFCjsQcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsFxQjK7rSQx",
        "outputId": "9e9c2dd9-a664-4ef3-8e3b-f80d35cd6eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10.], shape=(1,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "x=tf.Variable([5.0])\n",
        "with tf.GradientTape() as tape:\n",
        "  y=x**2\n",
        "dy_dx=tape.gradient(y,x)\n",
        "print(dy_dx)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note:variable haru jati sabbai ko recording tape aafai lae rakhxa\n",
        "but yedi kunai constant variable xa tyo chai use garnu parni xa differentiate garna vanae hamlae tape lai yesko ni record rakh hai vannu parxa or watch gaar vannu parxa using:\n",
        "\n",
        "    tape.watch(your-constant variable)"
      ],
      "metadata": {
        "id": "yeRsDqHMsgHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#constant lai watch gare na vanae k hunxa heram\n",
        "x=tf.constant([5.0])\n",
        "with tf.GradientTape() as tape:\n",
        "\n",
        "  y=x**2\n",
        "dy_dx=tape.gradient(y,x)\n",
        "print(dy_dx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZjmnXJ6sM1D",
        "outputId": "aa8d300c-f396-448b-dcc8-6ee5263548e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " so watch na garae constant lai deerivative none aauxa obviously"
      ],
      "metadata": {
        "id": "t1bNiwzitKlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#now watching constant\n",
        "x=tf.constant([5.0])\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y=x**2\n",
        "dy_dx=tape.gradient(y,x)\n",
        "print(dy_dx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvJwvLO2tAzt",
        "outputId": "eb2bd0f7-6fe4-4846-b38e-c98e169b0271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10.], shape=(1,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# also expression pani tei with tape vitrai hunu parxa\n",
        "natra ta tyo tape lae relationship record garnai paunna"
      ],
      "metadata": {
        "id": "XoCfYFSytkcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=tf.Variable([5.0])\n",
        "y=x**2\n",
        "with tf.GradientTape() as tape:\n",
        "  k=1\n",
        "\n",
        "dy_dx=tape.gradient(y,x)\n",
        "print(dy_dx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Zo98Nhtio9",
        "outputId": "66c1de8c-8d20-45c4-ea7e-5c6d12fbda82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#so tape vitra relationship ra watch garnu parni xa vanae tyo sabbai lekhni"
      ],
      "metadata": {
        "id": "cfte5rpuuvjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# implementation : in deep learning"
      ],
      "metadata": {
        "id": "TXd3R6dvu5DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import mse\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "yzKd2HkIt8dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model=Sequential()\n",
        "  model.add(Dense(1,input_shape=(2,)))\n",
        "  model.add(Dense(12))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer=Adam(learning_rate=0.1),loss=mse)\n",
        "  return model"
      ],
      "metadata": {
        "id": "dpCRcEjnvWLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=build_model()"
      ],
      "metadata": {
        "id": "d6RZ9icvvtUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm8o1g4Ov1b4",
        "outputId": "6baf5a65-a4be-4a6f-ccc2-f4680e02bb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 12)                24        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40 (160.00 Byte)\n",
            "Trainable params: 40 (160.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# note:model ko relationship record garni ho vane .predict ma hunxa jasto bhujam\n",
        "\n",
        "or simply model ko derivative wrt to each trainable variables garna ko lagi tape lae paila ta relation of output wrt to each parameters record garnu paryo\n",
        "tyo record garauni equation chai model.predict ma hunxa vanae ko or simply model.predict chai tape vitra lekhnu parxa\n",
        "\n",
        "aani variables lai watch chai .watch garai rakhnu pardaina as it is already variables ad already being watched by the tape"
      ],
      "metadata": {
        "id": "YGkJj588wYCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.constant([[1.0, 2.0]])\n",
        "targets = tf.constant([[2.0]])"
      ],
      "metadata": {
        "id": "ucT1wvrXzoF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# note yo muni ko vanae ko aafai lae .fit garako jasto ho\n",
        "#paila predict garna launi\n",
        "#aani prediction aanusar loss\n",
        "#aani derivative of loss wrt to each trainable paramenters\n",
        "with tf.GradientTape() as tape:\n",
        "    # Forward pass\n",
        "    predictions = model(inputs)\n",
        "    # Compute the loss\n",
        "    my_loss = mse(targets, predictions)\n",
        "\n",
        "# Compute gradients\n",
        "gradients = tape.gradient(my_loss, model.trainable_variables)"
      ],
      "metadata": {
        "id": "86b1hDngv7Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kzbsfd0x2ed",
        "outputId": "e2cb2dc6-6513-48f8-8863-e34a11127301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              " array([[16.479412],\n",
              "        [32.958824]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([16.479412], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 12), dtype=float32, numpy=\n",
              " array([[ 2.9560552 ,  2.2457519 , -3.106114  , -1.8236355 , -0.73855144,\n",
              "          5.7419133 ,  1.972916  , -5.091543  ,  3.7493927 ,  0.43415612,\n",
              "         -5.851799  , -3.7423937 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
              " array([ 2.4747047 ,  1.880064  , -2.6003287 , -1.5266831 , -0.6182891 ,\n",
              "         4.8069267 ,  1.6516554 , -4.2624598 ,  3.138859  ,  0.36346015,\n",
              "        -4.898919  , -3.1329997 ], dtype=float32)>,\n",
              " <tf.Tensor: shape=(12, 1), dtype=float32, numpy=\n",
              " array([[ 4.382568  ],\n",
              "        [ 2.3148072 ],\n",
              "        [-5.6461487 ],\n",
              "        [-4.5261545 ],\n",
              "        [-0.26272354],\n",
              "        [ 4.624916  ],\n",
              "        [ 0.96463186],\n",
              "        [-7.834239  ],\n",
              "        [ 6.1084003 ],\n",
              "        [-0.48243797],\n",
              "        [-6.9884067 ],\n",
              "        [-3.828957  ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([5.8500957], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#aaba yo aako aako gardient ko value aauasar tyo trainable paramenters update garna ko lagi\n",
        "optimizer=Adam(learning_rate=0.1)\n",
        "optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
        "#note optimizers lae chai tyo gradient apply garxa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeDiiH8dzfQB",
        "outputId": "e99960dd-5978-40b0-b4e5-ba3b87ce6115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "according to geeks for geeks:\n",
        "\n",
        "What is tf.GradientTape in TensorFlow?\n",
        "The tf.GradientTape class in TensorFlow is a Python tool used for calculating the gradients of a computation concerning certain inputs, typically tf.Variables. TensorFlow keeps track of relevant operations executed within the scope of a tf.GradientTape instance, recording them onto a “tape”. Upon calling the gradient() method on the tape, TensorFlow calculates the gradients of the recorded operations with respect to the specified inputs.\n",
        "\n",
        "tf.GradientTape is a context manager that records the operations performed on tensors. Tensors are the basic data structures in TensorFlow, similar to arrays or matrices. A tensor can have any number of dimensions, shape, and data type. tf.GradientTape can track any tensor that is watched, either explicitly or implicitly.\n",
        "\n",
        "Variables:\n",
        "\n",
        "By default, tf.GradientTape will automatically watch any trainable variables accessed while the tape is active. Trainable variables are the variables that can be modified by the optimizer during training. They are usually created by tf.Variable with the argument trainable=True. Non-trainable variables, such as constants, are not watched by default. To watch a non-trainable tensor, we can use the tape.watch() method. To stop watching a tensor, we can use the tape.stop_recording() method."
      ],
      "metadata": {
        "id": "ER2y46OK2aZo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ls2bi2mG0SxC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}